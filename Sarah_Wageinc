install.packages("freqparcoord")
library(freqparcoord)
data("prgeng", package = "freqparcoord")
help(prgeng)
#Check the data set
head(prgeng)     
str(prgeng)       
summary(prgeng)
######
help(prgeng, package = "freqparcoord")
data(prgeng)
# Examine the histogram of each variable to check the distribution and outliers,

#remove rows with missing values of wageinc, wkswrkd and agenote that in this project we want to inclued only employed people 
prgeng1 <- prgeng[prgeng$wageinc != 0, ]
prgeng2 <- prgeng1[prgeng1$wkswrkd != 0, ]
prgeng3 <- prgeng2[prgeng1$age != 0, ]
prgeng4 <- prgeng3[prgeng1$powspuma != 0, ]
prgeng5 <- prgeng4[prgeng1$age != 1, ]
prgeng5[!complete.cases(prgeng5), ]

# Remove rows with NA in specific column (e.g., wageinc)
cleaned_data <- prgeng5[!is.na(prgeng5$wageinc), ]
head(cleaned_data)
summary(cleaned_data)
head(cleaned_data)
######
##Examine the histogram of each variable to check the distribution and outliers,
# be on the look for potential data entry errors.
hist(cleaned_data$wageinc)
# There is outlier(extremly large)
##To make the graph clear, note that hist used for numerical data only
hist(cleaned_data$wageinc, breaks = 50, main = "Salary distribution", xlab = "Annual salary")
hist(cleaned_data$age, breaks = 50, main = "Age distribution", xlab = "Ages")#Normal with few oultier
hist(cleaned_data$wkswrkd, breaks = 50, main = "Weeks worked distribution", xlab = "Weeks worked")##Not normal at all

# Note: Use "na.action = na.exclude" to avoid lurking errors in R caused by NAs in the data.
# If "na.action = na.exclude" is not specified, the default way lm() handles missing
# data will result in outputs from predict(), fitted(), residuals(), etc. having
# a different length than the original data -- all rows with missing data are removed.
# Setting "na.action=na.exclude" asks R to pad the outputs from predict(), fitted(), 
# residuals(), etc. with NA for those rows with missing data, so all the above 
# outputs have the right correspondence. 

MODEL<-lm(wageinc ~ age+educ+wkswrkd, data=cleaned_data, na.action=na.exclude)
summary(MODEL)
# Q-Q plot of the model
qqnorm(residuals(MODEL))
qqline(residuals(MODEL))#This is much better than mod , I think we must use this and not include categorical variables
plot(fitted(MODEL), rstudent(MODEL))
################################
# Transform Y with log(), fit the new model, and repeat the diagnostics
LOGMODEL<-lm(cleaned_data$log.wageinc~.,data=cleaned_data)
# Residual plots of the log-transformed model
plot(fitted(LOGMODEL), rstudent(LOGMODEL))
######Violation of Linearity Assumption 
### Impression: Most of the heteroskedasticity has NOT been fix! 
# We can plot the residuals against the individual Xs again. 
plot(cleaned_data$wageinc, residuals(LOGMODEL))
plot(cleaned_data$age, residuals(LOGMODEL))
plot(cleaned_data$educ, residuals(LOGMODEL))
plot(cleaned_data$wkswrkd, residuals(LOGMODEL))
plot(cleaned_data$engl, residuals(LOGMODEL))
plot(cleaned_data$occ, residuals(LOGMODEL))###delete this variable
plot(cleaned_data$sex, residuals(LOGMODEL))
plot(cleaned_data$cit, residuals(LOGMODEL))
plot(cleaned_data$powspuma, residuals(LOGMODEL))###
plot(cleaned_data$yrentry, residuals(LOGMODEL))##?Do we need to use polynomial
# Q-Q plot of the log-transformed model
qqnorm(residuals(LOGMODEL))
qqline(residuals(LOGMODEL))
plot(fitted(LOGMODEL), rstudent(LOGMODEL))
abline(h=0, col="red")
# Impression
##The log model is not good enough by qqnorm
# You can use the following code to identify the outlier
plot(fitted(LOGMODEL), rstudent(LOGMODEL), type='n')
text(fitted(LOGMODEL), rstudent(LOGMODEL), names(rstudent(LOGMODEL)))
rstudent(LOGMODEL)[21] # double check
### I will stop working on log model (codes below belongs to log)

#-------------------------------------------------------------------------------
# Extra: Box-cox transformation

# Use the following code to find out the optimal power lambda value

lambda <- powerTransform(MODEL)$lambda
lambda
##When I tried MODEL the matrix is not invertable(error)
#######
Square transformation
m22 <- lm(sqrt(wageinc) ~ age+educ+wkswrkd, data = cleaned_data)
# Residual plot square transformed model
plot(fitted(m22), rstudent(m22))
##############
# Q-Q plot of the square transformed model
qqnorm(residuals(m22))
qqline(residuals(m22))
##much better than log transformation

###Extra code if we need to use later
y<-prgeng$wageinc
x1<-prgeng$age
x2<-prgeng$cit
x3<-prgeng$educ
x4<-prgeng$engl
x5<-prgeng$occ
x6<-prgeng$birth
x7<-prgeng$wkswrkd
x8<-prgeng$yrentry
x9<-prgeng$powspuma
x10<-prgeng$gender
nonnative<-cleaned_data[cleaned_data$yrentry >0,]
########
##Example: Two categorical predictors + one numeric predictor

cleaned_data$sex.factor <- factor(cleaned_data$sex, levels = c(1, 2), labels = c("Male", "Female"))
cleaned_data$engl.factor <- factor(cleaned_data$engl, levels = c(0,10,11,20,21,30,31,40,41), labels = c("A", "B","C","D","E","F","G","H","I"))
mt <- lm(cleaned_data$wageinc ~ cleaned_data$sex.factor + cleaned_data$engl.factor + cleaned_data$wkswrkd, data=cleaned_data)
summary(mt)
# Diagnostics
plot(predict(mt), rstudent(mt))
qqnorm(residuals(mt)); qqline(residuals(mt))

mt1 <- lm(cleaned_data$wageinc ~ cleaned_data$sex.factor + cleaned_data$engl.factor, data=cleaned_data)
summary(mt1)
plot(predict(mt1), rstudent(mt1))
qqnorm(residuals(mt1)); qqline(residuals(mt1))
#######################################################
##############################################################
#Example:(Explanation in my note)
cleaned_data$sex.factor <- factor(cleaned_data$sex, levels = c(1, 2), labels = c("Male", "Female"))
m11<-lm(cleaned_data$wageinc ~ cleaned_data$sex.factor)
summary(m11)
# Multiple regression
table(cleaned_data$wkswrkd)# table(cleaned_data$wkswrkd)is not continous fine ???
ms1 <- lm(cleaned_data$wageinc ~ sex.factor + educ,data=cleaned_data)
summary(ms1)

ms2 <- lm(cleaned_data$wageinc ~ sex.factor + wkswrkd + sex.factor:wkswrkd,cleaned_data)
summary(ms2)
table(cleaned_data$wkswrkd)
ms3 <- lm(cleaned_data$wageinc ~ sex.factor + wkswrkd ,cleaned_data)
summary(ms3)

# Observed data scatterplot: Male data

 plot(cleaned_data$wkswrkd[cleaned_data$sex.factor == "Male"], cleaned_data$wageinc[cleaned_data$sex.factor == "Male"], 
       +      col="blue", pch=3,
       +      xlab="Number of weeks worked", ylab="Annual Salary", )

# Observed data scatterplot: Add Female data
 plot(
   cleaned_data$wkswrkd[cleaned_data$sex.factor == "Female"], 
   (nor worked)wageinc[cleaned_data$sex.factor == "Female"], 
   col = "orange", 
   pch = 5,
   xlab = "Number of weeks worked", 
   ylab = "Annual Salary"
 )
 

# Add the male regression line(not worked)

new.data <- data.frame(cleaned_data$sex.factor="Male", cleaned_data$wkswrkd = seq(from=min(cleaned_data$wkswrkd, na.rm=T), to=max(cleaned_data$wkswrkd, na.rm=T), length.out=30))
                       
my.pred <- predict(ms1, newdata=new.data)

lines(new.data$wkswrkd, my.pred, col="blue", pch=3, lwd=3)
help(data.frame)

# Add the female regression line

new.data <- data.frame(sex.factor = "female",cleaned_data$wkswrkd = seq(from=min(cleaned_data$wkswrkd, na.rm=T), to=max(cleaned_data$wkswrkd, na.rm=T), length.out=30))
                       

my.pred <- predict(ms3, newdata=new.data)

lines(new.data$bytests, my.pred, col="orange", pch=5, lwd=3)
###############################################################################################################
# Legend

legend("bottomright", legend=c("Male", "Female"), col=c("blue", "orange"), pch=c(3, 5))
#########Google help
# Step 1: Plot male data
plot(
  cleaned_data$wkswrkd[cleaned_data$sex.factor == "Male"], 
  cleaned_data$wageinc[cleaned_data$sex.factor == "Male"], 
  col = "blue", 
  pch = 3, 
  xlab = "Number of weeks worked", 
  ylab = "Annual Salary"
)

# Step 2: Add female data to the same plot
points(
  cleaned_data$wkswrkd[cleaned_data$sex.factor == "Female"], 
  cleaned_data$wageinc[cleaned_data$sex.factor == "Female"], 
  col = "orange", 
  pch = 5
)

# Step 3: Fit a linear model for male data and add the regression line
male_model <- lm(wageinc ~ wkswrkd, data = cleaned_data, subset = (sex.factor == "Male"))
abline(male_model, col = "blue", lwd = 2)  # Blue line for male regression

# Step 4: Fit a linear model for female data and add the regression line
female_model <- lm(wageinc ~ wkswrkd, data = cleaned_data, subset = (sex.factor == "Female"))
abline(female_model, col = "orange", lwd = 2)  # Orange line for female regression

# Step 5: Add a legend to distinguish the points and lines
legend(
  "topright", 
  legend = c("Male", "Female"), 
  col = c("blue", "orange"), 
  pch = c(3, 5), 
  lwd = 2
)

##################################################################################################################
